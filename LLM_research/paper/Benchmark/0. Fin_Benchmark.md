
## QA 벤치마크
- **기초 QA**: FiQA (2018)
- **수리 reasoning QA**: FinQA (2021), TAT-QA (2021)
- **대화형 reasoning QA**: ConvFinQA (2022)
- **복잡한 구조 reasoning QA**: MultiHiertt (2023)
- **종합 벤치마크**: FinBen (2024)

금융 reasoning-heavy QA의 정석 라인업:  
**FinQA → ConvFinQA → MultiHiertt → FinBen**
+) **TAT-QA, FinChain**


|벤치마크|연도 / 학회|데이터 유형|주요 특징|
|---|---|---|---|
|**FiQA**|2018, WWW/WSDM|금융 뉴스, 발언|초기 금융 QA, opinion + sentiment 중심|
|**FinQA**|2021, EMNLP|보고서 Table + Text|Numerical reasoning + DSL program 제공|
|**TAT-QA**|2021, ACL|Table + Text|Cross reasoning, multi-modal QA|
|**ConvFinQA**|2022, EMNLP|Multi-turn QA (Table+Text)|대화형 numerical reasoning|
|**MultiHiertt**|2023, ACL Findings|Hierarchical table + text|구조적·복잡한 reasoning QA|
|**FinBen**|2024, arXiv|Multi-task (QA 포함)|금융 LLM 종합 벤치마크|
|**FinChain**|2025, arXiv|Symbolic QA + reasoning traces|**Verifiable Chain-of-Thought** 제공, Python trace + ChainEval 평가|

### 1. FiQA
[FiQA Challenge 2018 (WWW & WSDM)]
(Financial Question Answering, 2018 – WWW & WSDM workshops)

- 금융 뉴스, 마켓 코멘트, 보고서 등에서 **문장 단위 opinion mining** 과 **질의응답 태스크** 제공
- 금융 문서(뉴스 기사, 투자자 발언 등) → 질문, 문장, 레이블 (aspect, sentiment)
- QA 태스크는 간단한 문맥 기반 질의응답 수준
- reasoning-heavy는 아니고, **sentiment + 정보 검색형 QA** 성격이 강함

### 2. FinQA 
_FinQA: A Dataset of Numerical Reasoning over Financial Data_
(EMNLP 2021)
https://aclanthology.org/2021.emnlp-main.300.pdf

🌈 [FinQA](<./FinQA.md>)
- 금융 보고서(Table + Text)에서 **numerical reasoning**을 요구하는 QA
- 단순히 답만 주는 게 아니라 **DSL (Domain-Specific Language)** 기반 **reasoning program**까지 제공
- 구성: 
	- ~8K QA pairs (train/dev/test)
	- 입력: 보고서의 표(table)와 설명(text)
	- 출력: 정답(숫자 or span) + reasoning program (e.g., SUM, DIVIDE, DIFFERENCE)
- **계산형 reasoning** 연구의 기준점(Baseline: retriever + generator)
#### FinQA 2.0 
(unofficial extension)

- EMNLP 2021 FinQA에서 영감을 받아, 일부 연구자들이 비공식적으로 **더 긴 reasoning chain**을 요구하는 버전 제작
- “complex numerical reasoning over financial reports” 형태로 활용됨
- 공식 출판된 건 아니지만 **후속 연구에서 자주 인용**됨

### 3. TAT-QA 
_TAT-QA: A Question Answering Dataset over Tabular and Textual Data_
(ACL 2021)
https://aclanthology.org/2021.acl-long.254.pdf

- **Table-And-Text QA** → 금융 보고서에서 **표(table) + 텍스트(text)** cross reasoning
- 구성:
	- 약 16K QA pairs
	- 입력: 10K+ financial reports, 표와 본문 설명
	- 출력: 정답(span, number, option)
- reasoning 방식: table에서 값 추출 후, 본문 설명과 결합해야 정답 가능
- **멀티모달 reasoning QA** (table + text)


### 4. ConvFinQA 
_ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering_
(ACL 2022 Findings)
https://aclanthology.org/2022.emnlp-main.421.pdf

- **FinQA 확장판** → 단일 질문이 아니라 **multi-turn 대화형 QA**
- 구성 :
	- ~3.8K 대화 세션, 14K QA pairs
	- 입력: 이전 질의응답 + 보고서(Table/Text)
	- 출력: 정답 + reasoning program
- 이전 turn에서 얻은 정보(retrieval, 계산 결과)를 다음 turn reasoning에 활용해야 함
- **chain-of-reasoning**과 **대화 문맥 추적**이 동시에 필요


### 5. MultiHiertt 
 _MultiHiertt: Numerical Reasoning over Hierarchical Tabular and Textual Data in Finance_ 
(ACL 2023 Findings)
https://aclanthology.org/2022.acl-long.454.pdf

- 금융 보고서에 포함된 **복잡한 hierarchical tabular + textual data** 기반 QA
- 구성
	- 수천 개의 금융 리포트 QA
	- 입력: 여러 계층적 테이블 (e.g., Consolidated Balance Sheet, Income Statement)
	- 출력: 수치형/텍스트형 정답
- 테이블이 단순 2D 구조가 아니라 **계층적 구조(header 병합, multi-level)**
- reasoning 난이도가 가장 높은 금융 QA 데이터셋 중 하나
- 길이가 긴 문서와 복잡한 구조 → **retrieval + hierarchical reasoning** 필요



### 6. FinBen 
_FinBen: A Comprehensive Benchmark for Financial Domain Language Models_ 
(2024 – arXiv)

- 금융 LLM용 **multi-task benchmark** (QA, NLI, Summarization, IE, Reasoning 등 다수 태스크 포함) 
- 구성 :
	- 금융 뉴스, 리포트, 재무제표, 분석 보고서 → 여러 태스크용 데이터셋
	- QA도 포함되지만 단일 QA 중심은 아님
- 금융 NLP에서 SQuAD 같은 역할
- 다양한 태스크를 아우르므로 **LLM 전반 평가 벤치마크** 성격
- reasoning-heavy QA subset 포함

### 7. FinChain
*FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought*
(2025 – arXiv)

🌈 [FinChain](<./FinChain.md>)
- 기존 **FinQA (EMNLP 2021)** 는 단일 수식 기반 numerical reasoning 중심
- FinChain은 이를 확장해서 **multi-step numerical reasoning** (Chain-of-Thought style reasoning) 을 요구하는 QA 데이터셋
- 각 질문은 금융 보고서(Table/Text) 기반이고, 정답과 함께 **중간 reasoning chain**(intermediate steps)을 supervision으로 제공
- CoT 훈련 데이터셋으로 유용
