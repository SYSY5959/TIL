## 배경

### Loss Func
- 회귀: MSE
- 분류: Cross Entropy
→ loss func 최적화!! convex
	- 함수 간단(convex) : 편미분해서 0 인 값 찾기
	- 함수 convex X (복잡) : Gradient Descent

#### 시간복잡도
`O(1)` < `O(n)` < `O(logn)` < `O(nlogn)` < `O(n²)` < `O(N!)`


## 선형 회귀
- 1개 이상의 독립적인 input variable, 1개의 output target variable
- Cost func:  (LSE) 잔차 제곱합 최소화 → 최적화하는 베타 찾기. 

규제 선형회귀 : 오버핏팅 방지 
[릿지]
- L2 norm : 제곱합
- features 버리기 불가능
- Analytic sol 존재 (손실함수를 베타에 대해 미분 해서 0 되는 베타 찾기 가능 )

[라쏘]
- L1 norm : 절댓값 합
- feature 버리기 가능
- Analytic sol 존재 X → Gradient Descent

## Gradient Descent
- Gradient: func이 가장 빠르게(Duf 최대가 되려면, cos세타 = 1. 세타 = 0 → 같은 방향 ) 증가하는(+ → 오른쪽으로 가야 함수값 증가. - → 왼쪽으로 가야 함수값 증가) 방향 
- G.D : gradient의 반대 방향으로 조금씩 움직여 local minimum 찾는 최적화 알고리즘
→ 모든 train set에 대한 iteration → 비용. 시간 증가

#### Stochastic G.D
- 랜덤으로 뽑은 하나의 데이터에 대한 편미분 값만 계산
→ 빠르지만 Unstable
#### SGD with Minibatch
-랜덤 샘플 M개. 

## Logistic Regression

- 이진 분류 문제에 적합하여, 특정 클래스에 속할 확률 예측
- 시그모이드를 이용하여 확률 예측
- loss func: Binary cross entropy → G.D 이용하여 두 그룹 나누는 직선 $W^{T}x+b$의 W, b (계수) 찾기


## SVM
- margin : Decision Boundary와 가장 가까운 데이터 사이의 거리 (SV & DB 사이 거리)
- Hard Margin SVM : 모든 데이터 올바르게 분류. 오류 허용 X → 과적합
- Soft Margin SVM : 오류 허용, 패널티 부과 → slack var 크사이 추가. 하이퍼파라미터 C로 패널티 조절 (C 커질수록 오류에 민감하게 반응. 마진 좁고, 오버피팅 가능)

### Hard Margin SVM
- 클래스를 구분하는 최적의 초평면을 찾는 것 → SV와 초평면 사이 거리 margin 최대화
- 초평면은 서포트 벡터들로 결정 됨 (초평면에 가장 근접한 데이터 점들)
- loss func: 2Margin 최대화 → $2/|W|$ 최대화 → |W| 최소화 → $\frac{1}{2}|W|^2$  최소화 하는 W, b 찾기
→ Lagrange Multiplier 이용하여 최적화. 

#### Lagrange Multiplier
- Lagrange Multiplier은 Gradient f와 Gradient g가 평행하다는 것 이용
 Why?
 1. Sol은 tangent point (접점)에서 생기기 때문에 항상 평행
 2. ???????????????????

[Primal form]
lagrange func 최소화. W,b에 대한 편미분 = 0 에서 얻은 식들을 바탕으로 식을 정리하면 알파에 대한 식 나옴. (여기서 알파가 L.M) 

[Dual form]
위에서 정리한 식(Lagrange Dual func)을 최대화. (duality gap 줄이기 위해)

#### KKT condition

$$
\nabla f(\mathbf{w^*}) - \sum_{i=1}^{N} \alpha_i \nabla g_i(\mathbf{w^*}) = 0, \quad \text{(stationary)}
$$

$$
\alpha_i g_i(\mathbf{w^*}) = 0, \quad \forall i \in [1, N] \quad \text{(complementary slackness)}
$$

$$
\alpha_i \geq 0, \quad \forall i \in [1, N] \quad \text{(dual feasibility)}
$$

$$
g_i(\mathbf{w^*}) \geq 0, \quad \forall i \in [1, N] \quad \text{(primal feasibility)}
$$


#### PSD
Multivariate func(다변수 함수)의 convex 확인하고 싶어서!!!
	single variable func(일변수 함수)는 두번 미분한 게 양수면 convex

- Hessian Matrix : x에 대해 두번 미분한 값
- Hessian Matrix가 PSD(positive semi definite) 이면 convex하다. 
- PSD : 임의의 실수 x에 대해 $x^{T}Hx >= 0$ 

#### KKT condition 푸는 방법
Step 1. Solve Minimization Problem : Primal form
	w, b, alpha 에 대한 함수 (convex & continuous w,b)

Step 2. Make Lagrange Dual Func : Dual form
	위에서 구한 L(w, b, alpha)에 Optimal W* 대입해서 나온 식. 

Step 3. Find alpha that maximizes Dual form
	QP(Quadratic Programming) 이용해서 Optimal alpha 구하기

→ Non S.V : alpha = 0 / S.V : alpha != 0 → S.V에 대해서만 식
(margin은 SV로만 정의되기 때문에 나머지 애들은 고려 대상 X)

여기서 구한 알파를 바탕으로 Optimal W, b 구하기 → D.B 다 구하게 됨

### Soft Margin SVM
- error cases 허용하고 패널티 부과 
→ Slack Variable
Non SV : Slack Variable = 0
SV on margin : Slack Variable = 0
SV inside and outside the margin(error): Slack Variable > 0

C: 하이퍼 파라미터 → 클수록 DB 넘는 애들 패널티 크게 부여 → Hard Margin SVM과 가까워짐

Lagrange Multiplier 이용해서 풀면 식 다 똑같은데 마지막에 제약 조건 하나만 더 붙음: alpha <= C


### Non-linear SVM
Input space → Feature space (DB 구하기)
nonlinear(mapping) function으로 input space를 고차원으로 보낼 수 있음 

같은 방식으로 Lagrange Multiplier 이용해서 풀면 SVM DB 구할 수 있음
→ 근데 여기서 $\phi(x)^T\phi(x)$ 만 필요함 (내적밖에 안해!! - Scalar value만 필요)

그래서 굳이 Transform 하지 않고도 내적값을 구할 수 있음. 
→ Kernel Trick

#### Kernel Trick
- polynomial kernel
- RBF kernel → 무한 차원으로 mapping
- Gaussian kernel
- Sigmoid kernel

[RBF kernel]
- 두 개의 데이터 포인트 $x_i​$ 와 $x_j$​ 사이의 유사도를 가우시안 함수(정규 분포 기반)로 측정
- 테일러 급수 이용 → 무한차원으로 mapping → 성능 Good
- $\gamma$ : 하이퍼 파라미터 → 높을수록 정확도 높고 오버핏팅



## Neural Network
### 퍼셉트론
- 단순한 이진 분류 모델
- input에 가중치 곱하고 합산하여 활성화 함수를 거쳐 결과 출력
- cost func: MSE → G.D 활용해 W, b 찾기 (가중치와 bias)
- 한계 : 선형적으로 분리 가능한 데이터에서만 작동 →XOR 문제와 같은 

### Multi layer NN
- 비선형 문제 효과적으로 해결 → 이미지 인식, 자연어 처리 Good 
- 여러개의 은닉층

### Back Propagation
- feed forward를 통해 input 에서 output 통과시켜 예측값 계산
- loss func를 이용해 오차 계산
- Back Propagation → 체인룰을 통해 각 가중치의 Gradient 계산
- G.D를 통해 가중치 업데이트 

#### Delta Rule
오차 최소화하기 위해 가중치 업데이트하는 규칙
퍼셉트론, 다층 신경망의 역전파 알고리즘에서 사용됨


### SGD 
- 1개의 샘플 사용해 기울기 계산 → 가중치 업데이트
- 빠르지만 불안정

### GD with Mini batch
- M개 미니 배치. 데이터 무작위 선택. 

### 다른 NN

- LSTM : RNN의 한 종류로 장기 의존성 문제(입력,출력 사이 거리 멀어질수록 연관관계 적어짐) 해결. 셀 상태(Cell state)와 게이트 구조(Input, Forget, Output Gate)를 사용하여 정보 선택적으로 기억. 복잡한 구조. 계산 비용 높음
- GRU : LSTM의 Forget, Input gate 통합하여 하나의 update gate. 더 간단한 구조로 빠른 학습시간과 낮은 계산 복잡도
- BERT : 사전 훈련 언어모델. 양방향 학습으로 문맥 더 잘 이해. Transformer의 인코더 구조만 사용. 사전학습방법은 MLM(단어 마스킹,예측), NSP(다음 문장 예측)

#### CNN
- 이미지, 영상데이터 처리하는 신경망 구조
- 합성곱, 풀링, 완전 연결 레이어
- 합성곱: 입력 이미지에 필터 적용하여 특징 맵 추출
- 풀링: 특징 맴의 크기를 줄이고 불필요한 정부 줄여 연산량 감소
- 여러 합성곱, 풀링 레이어 반복 → 고차원적인 특징 추출
- 완전 연결: 추출된 특징 바탕으로 이미지 특정 클래스로 분류

#### RNN
- 순차적인 데이터 처리하는 신경망 구조.
- 이전 단계 출력을 현재 단계 입력으로 활용. 순서 고려하여 패턴 학습
- 입력층 → 순환층(과거 정보 기억) → 출력층
- 모든 시간 단계에서 동일한 가중치 사용
- Hidden state에 이전 단계 정보를 현재 단계에 전달
- BPTT(Back Propagation Through Time) : 현재 시점에 발생한 에러를 과거 시점까지 전달해서 학습
- →시퀀스 길어질수록 Gradient Vanishing 문제 (먼 과거까지 학습 과정에서 곱해지는 G 작아져 기울기 소실)

#### LSTM
- RNN의 장기 의존성 문제 해결
- 기억 셀 추가하여 중요한 정보 오래 기억. 망각 게이트 통해 불필요한 정보 삭제
- 셀 상태와 게이트 구조를 통해 정보 선택적 기억. 삭제
- 망각 게이트와 입력 게이트에서 선택된 정보가 셀 상태(Cell State)를 업데이트
- 기울기 소실 문제 해결. 중요 정보 선택적 기억

#### GRU
- LSTM처럼 장기 의존성 문제 해결. LSTM보다 훈련 속도 빠름
- 입력, 망각 게이트 하나로 통합하여 구조 단순화 : 업데이트, 리셋 게이트


## ML with probability
#### MLE
Likelihood : 데이터가 주어졌을 때, 특정 분포가 이 데이터를 설명할 가능성
MLE : likelihood 를 최대화하는 파라미터

log likelihood 최대화 == negative log likelihood 최소화


## Naive Bayes Classifier / Bayesian Network

### Naive Bayes Classifier
#### Bayes' Thm
Posterior 사후확률(구하기 어려움)  = likelihood (Y가 주어졌을 때 X가 나올 확률) x Prior (사전확률)

- Marginalization: Hidden var이 가질 수 있는 모든 경우의 값 다 더하기
- Normalization: y 가 가질 수 있는 모든 경우의 값 다 더하기 (합이 1이 될 수 있도록 확률 정규화 / softmax)

#### Conditional Independence (CI)
시간복잡도 : $O(d^{n})$ → 모든 변수 독립이면 $O(nd)$

- C가 특정 값으로 관찰되었다는 조건 하에 X,Y 독립

[CI / NB Assumption]
클래스 Ck가 주어지면, $x_{j}$에 대한 정보는 $x_{i}$ 와 아무 관련 X

#### Bayesian Decision Theory
X가 주어졌을 때, Posterior (사후확률) 가 최대가 되는 클래스 k로 분류 해주겠다~~

### Bayesian Network

#### D - seperation
Bayes net에서 X와 Y가 CI given evidence z이면, X,Y는 z에 의해 d - seperation

## Gaussian Mixture Model & EM

- latent variable z : 직접 관측할 수 없지만, 데이터 패턴을 설명하는 변수. 우리가 관측한 데이터 x에 영향
→ 데이터를 **저차원(latent space)으로 변환**하여 계산 효율성을 높일 수 있음
PCA(주성분 분석), 오토인코더(Autoencoder), 변분 오토인코더(VAE)   등의 모델에서

### EM Algorithm
#### 1️⃣ E-Step (Expectation Step, 기대 단계)
- 현재 파라미터 값 $\theta^{(t)}$ 를 기반으로 **잠재 변수 Z 의 기대값(z 분포)을 계산**
- 즉, **현재 모델이 주어졌을 때, 각 데이터가 특정 잠재 변수에 속할 확률을 계산**

#### 2️⃣ M-Step (Maximization Step, 최대화 단계)
- **E-Step에서 계산한 기대값을 이용하여 파라미터(θ)를 업데이트**
- 즉, **가능도(likelihood)를 최대화하도록 모델의 파라미터를 조정**

![[./Images/Pasted image 20250312210845.png]]

### GMM
여러 정규분포를 섞어 놓은 모델이다. 
(데이터의 확률을 각 정규분포의 가중 평균으로 봄)

데이터가 어느 정규분포에서 생성되었는지  → latent var. 

#### 1️⃣ E-Step → latent var 분포 구하기
- 현재 파라미터 $\theta^{(t)} = (\pi_k, \mu_k, \Sigma_k)$ 를 이용해 **책임도(responsibility) $r_{ik}$​ 계산**
- $r_{ik}$ 는 데이터$x_i​$가 k 번째 가우시안에서 생성될 확률

#### 2️⃣ M-Step → 파라미터 업데이트 
- E-Step에서 계산한 책임도를 이용하여 새로운 $\pi_k, \mu_k, \Sigma_k$ 업데이트

### k - means clustering
E step: 데이터를 가장 가까운 centroid 에 할당
M step: update centroid

### EM Algorithm in General
- log likelihood $lnP(X|\theta)$ 
- jensen's inequality, 베이즈 정리, KL Divergence
 $$lnP(X|\theta) \geq lnP(X|\theta) - KL(q(z) || p(z | x,\theta))$$ 
#### KL Divergence

$$D_{KL}(Q \parallel P) = \sum_{x} Q(x) \log \frac{Q(x)}{P(x)}$$

💡 KL Divergence는 $D_{KL}(Q || P) \geq 0$를 만족하며, 두 확률 분포가 같아질수록 $D_{KL}​$값이 **0** 에 가까워진다.

Step 1. $\theta^{0}$ 초기화
Step 2. E - step : t번째 iteration에서 z 분포 찾기 → q(z) 최적화
Step 3. M - step : 파라미터 $\theta^{t}$ update → 세타 최적화


## Variational Autoencoder (VAE)

3가지 문제 정의. encoder - decoder 구조로 풀어냄
P1 : prior p(z) 정의 → 가장 간단하게 선택 (Unit Gaussian)
P2 : p(x|z) 분포 정의 → decoder 구조 만듬
P3 : z에 대한 적분 정의

### 과정
1. x 를 입력 받아서, 인코더에 넣어서, $\mu, \Sigma$  추정 (z의 분포)
2. z의 분포를 디코더에 넣어서 x의 분포를 다시 모델링
3. p(x) 분포에서 x 뽑기. 샘플링
4. x likelihood (ELBO) 최대화하는 파라미터(인코더와 디코더's) 추출
5. 역전파 학습. 인코더와 디코더는 역전파로 한번에 학습됨 (ELBO 최대화 되도록)
	미분 불가능 : z의 분포에서 샘플링 했기 때문 
	→ reparameterization trick : ϵ 을 따로 샘플링한 후 μ 와 σ 를 통해 변환하는 방법 사용
	→ 역전파 가능

- 인코더 : latent var z 를 정규분포로 맵핑, x를 평균과 분산을 예측해 확률 분포로 표현
- 디코더 : z 입력으로 받아 원본 데이터 분포 예측

✅ **로그 가능도 $\log p(x)$ 를 직접 계산하기 어려우므로, 이를 근사적으로 최적화하기 위해 ELBO를 최대화함**  
✅ **ELBO를 최대화하면 KL Divergence를 최소화할 수 있어, 잠재 변수를 표준 정규 분포로 정렬할 수 있음**


### Autoencoder (AE)
input x를 latent var z로 차원 축소하고, 다시 output x 생성 (비지도 학습)
VAE: 확률분포 P(x) 얻는 것이 목적
AE : latent var z를 잘 구하는 것이 목적 (차원축소)

just 구조만 비슷

### 활용 분야
- 이미지 생성
- 데이터 증강 ; 새로운 데이터 생성
- 강화 학습


## GAN 
**GAN(Generative Adversarial Network)** 는 **생성자(Generator)와 판별자(Discriminator)** 가 서로 경쟁(Adversarial)하며 학습하는 **생성 모델(Generative Model)**

✅ **목표:**
- **Generator(생성자)**: 실제 데이터와 유사한 데이터를 생성하는 역할
- **Discriminator(판별자)**: 실제 데이터와 가짜 데이터를 구별하는 역할
- **두 네트워크가 서로 경쟁하며 학습하여 더 정교한 데이터를 생성하도록 발전함**

### Generator (G, 생성자)

- **랜덤 노이즈 z 를 입력받아 실제 데이터처럼 보이는 샘플을 생성**
- 목표: 판별자를 속여 **가짜 데이터를 실제 데이터처럼 만들기**
$$\text{Generated Data}G(z)=Generated Data$$

**입력**: 랜덤한 노이즈 벡터 z (ex: 정규 분포 $\mathcal{N}(0,1)$)  
**출력**: 가짜 이미지 (Fake Image)

### Discriminator (D, 판별자)

- **입력 데이터를 보고 실제(real)인지 가짜(fake)인지 판별**
- 목표: **실제 데이터는 1(Real), 생성된 데이터는 0(Fake)로 분류**

$$D(x) = P(\text{Real} | x)$$

**입력**: 실제 데이터 또는 생성된 데이터  
**출력**: 0~1 사이의 확률 값 (1: Real, 0: Fake)


### GAN의 학습 과정

💡 GAN은 생성자(G)와 판별자(D)가 서로 경쟁하면서 학습 진행

1️⃣ **Step 1: 판별자(D) 학습**

- 실제 데이터 x 에 대해 **D(x) → 1 (Real)**
- 생성된 데이터 G(z) 에 대해 **D(G(z)) → 0 (Fake)**
- 판별자는 **진짜와 가짜를 더 잘 구분하도록 학습**됨.

2️⃣ **Step 2: 생성자(G) 학습**

- 생성자는 **D(G(z))** 가 **1** 에 가깝도록 학습해야 함.
- 즉, 판별자가 가짜 데이터를 진짜로 착각하도록 학습됨.

3️⃣ **Step 3: 반복 학습 (G와 D가 서로 경쟁)**

- **생성자는 더 정교한 가짜 데이터를 생성**하려 하고,
- **판별자는 이를 구별하려고 하면서 서로 발전**
- 두 네트워크가 균형을 이루면 **실제 데이터와 유사한 고품질 데이터를 생성**할 수 있음.

### Loss func
GAN의 학습 목표는 **생성자는 판별자를 속이고, 판별자는 이를 정확히 구별하는 것**입니다.

GAN의 **손실 함수**는 **게임 이론의 최소-최대(minimax) 최적화 문제**로 정의됩니다.

$$\min_G \max_D V(G, D)$$

### 모드 붕괴(Mode Collapse)

💡 **모드 붕괴(Mode Collapse)** 란 **GAN(Generative Adversarial Network)에서 생성자가 특정한 데이터 패턴만 학습하여 다양한 데이터를 생성하지 못하는 문제**입니다.

✅ 이상적으로, **GAN의 생성자(Generator)는 훈련 데이터의 전체 분포를 학습해야 하지만**,  
✅ 모드 붕괴가 발생하면 **일부 패턴만 반복해서 생성하고, 데이터의 다양성이 사라지는 문제**가 발생합니다.


## Diffusion model
데이터를 점진적으로 노이즈로 변환한 후, 이를 다시 복원하며 학습하는 확률적 생성 모델
→ 생성 모델 중 하나. 최고 품질의 이미지 생성
→ VAE보다 선명한 이미지, GAN보다 더 안정적인 학습 가능.

GAN, VAE와 달리, 디퓨전 모델은 직접적으로 데이터 분포를 학습하는 것이 아니라, 
점진적으로 변화하는 확률 과정 (마르코프 체인)을 기반으로 학습
노이즈 추가하며 데이터 분포 부드럽게 만들고, 이를 점진적으로 복원하는 방식이 더 안정적인 학습 가능하게 함.
💡 **즉, 노이즈를 추가하면서 데이터의 핵심 구조를 학습하고, 이를 복원하면서 새로운 데이터를 생성할 수 있게 만듦.**

Diffusion Model의 핵심은 **노이즈에서 데이터를 복원하는 과정이 확률적으로 이루어진다는 점**
즉, 같은 과정으로 노이즈를 제거해도 **항상 정확히 같은 결과가 나오지는 않음**.

- 고해상도 이미지 데이터를 직접 학습하는 것은 어렵지만, **노이즈를 추가하여 점진적으로 단순한 형태로 변형하면 학습이 쉬워짐!**

> ✅ **즉, 노이즈 추가는 데이터의 복잡성을 줄여주므로, 모델이 안정적으로 학습할 수 있음.**

### Forward Process


원본 데이터 $x_0​$ 에 **점진적으로 가우시안 노이즈(Gaussian Noise) 추가**하여 노이즈 데이터 $x_T​$ 생성
T 단계 후에는 완전한 정규 분포(백색 노이즈)가 됨

- 모델이 학습할 필요 없음, 원본 정보가 사라짐

- 근데 여기서 그냥 이전 데이터에 노이즈를 추가하면, 노이즈가 무한대로 쌓임
→ 이전 데이터를 좀 덜어내고 노이즈 추가 $X_{t} = \sqrt{1-\sigma_{t}^2}X_{t-1}+\sigma_{t}\epsilon$

💡 **목표: 원본 데이터를 점진적으로 정규 분포(Gaussian Distribution)로 변환하는 것**


#### 🚀 Forward Process의 역할

✅ 원본 데이터 분포를 점진적으로 정규 분포로 변환  
✅ 데이터를 단순한 확률 분포로 만들기 때문에 학습이 용이  
✅ 디퓨전 모델이 **정규 분포에서 샘플링한 데이터를 다시 원본 데이터로 변환할 수 있도록 학습 가능**


### Reverse Process
노이즈 데이터 $x_T​$ 에서 점진적으로 노이즈를 제거하여 원본 데이터를 복원
노이즈 제거를 담당하는 신경망 $\epsilon_\theta(x_t, t)$ 을 학습

💡 **목표: 정규 분포에서 점진적으로 노이즈를 제거하여 원본 데이터로 복원하는 것**

#### 🚀 Reverse Process의 역할

✅ **Forward Process를 역으로 수행하여 원본 데이터 복원**  
✅ **정규 분포에서 샘플링된 데이터도 원본과 같은 분포를 따르는 새로운 데이터로 변환 가능**  
✅ **학습된 노이즈 제거 네트워크 $\epsilon_\theta(x_t, t)$가 핵심 역할**

## DM vs VAE vs GAN

| 특징              | Diffusion Model               | GAN                            | VAE           |
| --------------- | ----------------------------- | ------------------------------ | ------------- |
| 이미지 품질          | ⭐⭐⭐⭐⭐ (최고)                    | ⭐⭐⭐⭐ (좋음)                      | ⭐⭐⭐ (흐릿함)     |
| 학습 안정성          | ✅ 매우 안정적                      | ❌ 불안정 (모드 붕괴 발생 가능)            | ✅ 안정적         |
| 다양한 샘플 생성 가능 여부 | ✅ 가능                          | ❌ 모드 붕괴 가능                     | ✅ 가능          |
| 샘플링 속도          | ❌ 느림 (100~1000 step 필요)       | ✅ 매우 빠름 (1 step)               | ✅ 빠름          |
| 학습 난이도          | ✅ 쉽고 안정적                      | ❌ 어렵고 튜닝이 필요                   | ✅ 쉬움          |
| 응용 분야           | 고품질 이미지 생성, 텍스트-이미지 변환, 영상 생성 | 초해상도(Super Resolution), 스타일 변환 | 데이터 압축, 이상 탐지 |

💡 **디퓨전 모델은 학습이 안정적이며 최고 품질의 이미지를 생성하지만, 매우 느린 속도가 단점.** GAN은 빠르지만 학습이 불안정하며, VAE는 안정적이지만 품질이 낮음.

| 모델                                | 주요 개념                                                 | 사용 방식                                                 |
|-------------------------------------|----------------------------------------------------------|----------------------------------------------------------|
| **Diffusion Model**                 | 데이터에 점진적으로 노이즈를 추가 후 제거하는 방식으로 생성 | 노이즈를 추가한 후 점진적으로 원본 데이터로 복원          |
| **GAN (Generative Adversarial Network)** | 생성자(Generator)와 판별자(Discriminator)가 경쟁하면서 학습 | 판별자가 생성된 데이터와 실제 데이터를 구별하도록 학습     |
| **VAE (Variational Autoencoder)**   | 데이터를 잠재 공간(latent space)의 확률 분포로 압축 후 샘플링하여 생성 | 인코더가 데이터의 확률 분포를 학습하고, 디코더가 원본 데이터를 복원 |

### 데이터 생성 방식
✅ **Diffusion Model**은 점진적으로 데이터를 생성하므로 학습이 안정적이며 고품질의 샘플을 만들지만, **매우 느림**  
✅ **GAN**은 가장 빠르게 샘플을 생성할 수 있지만, 학습이 불안정하며 모드 붕괴(Mode Collapse) 발생 가능  
✅ **VAE**는 학습이 안정적이지만, 생성 이미지의 품질이 상대적으로 낮음 (흐릿한 이미지)

| 모델              | 생성 과정                                         | 샘플링 방식                                      |
|-----------------|------------------------------------------------|-----------------------------------------------|
| **Diffusion Model** | 데이터를 점진적으로 노이즈로 변환한 후 다시 복원 | 여러 단계(수백~수천 단계)로 생성                  |
| **GAN**         | 생성자가 판별자를 속이는 방향으로 학습               | 단 한 번의 forward pass로 생성                  |
| **VAE**         | 데이터를 잠재 공간에 매핑 후 복원                   | 정규 분포에서 샘플링한 값을 디코더로 복원         |

다음은 해당 이미지를 Obsidian에서 사용할 수 있도록 마크다운 표로 변환한 것입니다:

### 학습 방식
✅ **Diffusion Model**은 학습이 GAN보다 **훨씬 안정적**이지만 **매우 느림**  
✅ **GAN**은 학습이 불안정하고 조정해야 할 하이퍼파라미터가 많음  
✅ **VAE**는 학습이 안정적이지만, 생성된 이미지가 덜 선명함

| 모델              | 학습 방법                                       | 손실 함수                                              |
|-----------------|----------------------------------------------|-----------------------------------------------------|
| **Diffusion Model** | 노이즈를 점진적으로 추가 & 제거하는 과정을 반복  | MSE(Mean Squared Error) 기반 손실                    |
| **GAN**         | 생성자(Generator)와 판별자(Discriminator)가 서로 경쟁 | Adversarial Loss (Binary Cross Entropy)            |
| **VAE**         | 인코더가 데이터를 정규 분포로 매핑하고 디코더가 복원  | ELBO (Reconstruction Loss + KL Divergence)         |

### Diffusion Model, GAN, VAE의 공통점

#### ✅ (1) 모두 생성 모델 (Generative Model)

- Diffusion Model, GAN, VAE는 모두 **새로운 데이터를 생성할 수 있는 모델**
- 학습 데이터 분포를 학습한 후, 샘플링을 통해 새로운 데이터를 만들어냄

#### ✅ (2) 잠재 공간(Latent Space) 개념 사용

- **VAE**는 명시적으로 정규 분포를 이용해 잠재 공간을 학습
- **GAN**은 Generator의 입력을 잠재 공간의 랜덤 노이즈로 사용
- **Diffusion Model**은 데이터 자체를 점진적으로 정규 분포로 변환하여 잠재 공간을 학습

#### ✅ (3) 다양한 응용 분야에서 사용

- **이미지 생성 (AI 아트, 스타일 변환)**
- **텍스트-이미지 생성 (DALL·E, Stable Diffusion)**
- **영상 생성 (비디오 합성, 애니메이션)**
- **의료 데이터 분석 (CT, MRI 영상 복원)**
- **음성 합성 (Text-to-Speech, 음성 변환)**